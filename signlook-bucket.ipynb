{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"signlook-bucket.ipynb","provenance":[{"file_id":"https://github.com/cloud-annotations/google-colab-training/blob/master/object_detection.ipynb","timestamp":1607959735419}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TZSL793i7KuM"},"source":["# Cài đặt - liên kết tới api của IBM \n","**Chú ý** các phiên làm việc chỉ lưu trữ trong 12 tiếng, và tự động xóa sau khi kết thúc phiên, nếu muốn lưu trữ trên drive, hãy chỉnh sửa code.\n"]},{"cell_type":"code","metadata":{"id":"GmloKE6Qx8Lu"},"source":["credentials = {\n","  \"bucket\": \"signlook-bucket\",\n","  \"access_key_id\": \"3af70ddf83ff47688873205c0b8801f5\",\n","  \"secret_access_key\": \"db0ab6972b55864d1b57b52f1657139f1830087b4d0cef6e\",\n","  \"endpoint_url\": \"https://s3.us.cloud-object-storage.appdomain.cloud\"\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVPzEKoLuEHy"},"source":["NUM_TRAIN_STEPS = 500\n","MODEL_TYPE = 'ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18'\n","CONFIG_TYPE = 'ssd_mobilenet_v1_quantized_300x300_coco14_sync'\n","\n","import os\n","CLOUD_ANNOTATIONS_MOUNT = os.path.join('/content', credentials['bucket'])\n","ANNOTATIONS_JSON_PATH   = os.path.join(CLOUD_ANNOTATIONS_MOUNT, '_annotations.json')\n","\n","CHECKPOINT_PATH = '/content/checkpoint'\n","OUTPUT_PATH     = '/content/output'\n","EXPORTED_PATH   = '/content/exported'\n","DATA_PATH       = '/content/data'\n","\n","LABEL_MAP_PATH    = os.path.join(DATA_PATH, 'label_map.pbtxt')\n","TRAIN_RECORD_PATH = os.path.join(DATA_PATH, 'train.record')\n","VAL_RECORD_PATH   = os.path.join(DATA_PATH, 'val.record')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3XINCKkPshgz"},"source":["# Cài đặt object detection api\n","Git clone file về cloud.\n","\n","### Gói phụ thuộc\n","Sử dụng các gói để vận hành khả năng xử lý của colab trên cloud.\n","\n","### Protocol Buffers\n","Dùng để cài đặt tf object api và biên dịch.\n","\n","### Environment\n","Khai báo đường dẫn của object api để python có thể nhận diện."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o33_jgwGm3NV","executionInfo":{"status":"ok","timestamp":1608562651617,"user_tz":-420,"elapsed":16762,"user":{"displayName":"Backdoor Cynet","photoUrl":"","userId":"06118184154984968533"}},"outputId":"64c59dd3-0743-44c1-9280-8ec6090e3ad3"},"source":["%tensorflow_version 1.x\n","import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/cloud-annotations/models\n","\n","!pip install cloud-annotations==0.0.4\n","!pip install tf_slim\n","!pip install lvis\n","!pip install --no-deps tensorflowjs==1.4.0\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","pwd = os.getcwd()\n","os.environ['PYTHONPATH'] += f':{pwd}:{pwd}/slim'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Cloning into 'models'...\n","remote: Enumerating objects: 2282, done.\u001b[K\n","remote: Counting objects: 100% (2282/2282), done.\u001b[K\n","remote: Compressing objects: 100% (1976/1976), done.\u001b[K\n","remote: Total 2282 (delta 555), reused 947 (delta 280), pack-reused 0\u001b[K\n","Receiving objects: 100% (2282/2282), 30.55 MiB | 32.83 MiB/s, done.\n","Resolving deltas: 100% (555/555), done.\n","Collecting cloud-annotations==0.0.4\n","  Downloading https://files.pythonhosted.org/packages/33/db/7bd769f9b1ed088088d30883fe79cbb3a0f300942a088e1467ff6b5792d5/cloud_annotations-0.0.4-py3-none-any.whl\n","Installing collected packages: cloud-annotations\n","Successfully installed cloud-annotations-0.0.4\n","Collecting tf_slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\u001b[K     |████████████████████████████████| 358kB 11.7MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n","Collecting lvis\n","  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.15.0)\n","Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.29.21)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.8.1)\n","Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.3.1)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.19.4)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from lvis) (3.2.2)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis) (4.1.2.30)\n","Installing collected packages: lvis\n","Successfully installed lvis-0.5.3\n","Collecting tensorflowjs==1.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/73/f7ee6edced75b7dfe43916203f1b2e85dd14cba087a090e6372cbd82e462/tensorflowjs-1.4.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n","\u001b[?25hInstalling collected packages: tensorflowjs\n","Successfully installed tensorflowjs-1.4.0\n","/content/models/research\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wS1ZDbJ660Wv"},"source":["# Kiểm tra cài đặt\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iM8sOHwL64Rp","executionInfo":{"status":"ok","timestamp":1608562660811,"user_tz":-420,"elapsed":25909,"user":{"displayName":"Backdoor Cynet","photoUrl":"","userId":"06118184154984968533"}},"outputId":"42e78ac1-2655-43c0-f13d-da2dfc2c851a"},"source":["!python object_detection/builders/model_builder_tf1_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running tests under Python 3.6.9: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n","[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params0 (True)\n","[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n","[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params1 (False)\n","[ RUN      ] ModelBuilderTF1Test.test_create_experimental_model\n","[       OK ] ModelBuilderTF1Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n","[       OK ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n","[       OK ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n","[       OK ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n","[       OK ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n","[       OK ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF1Test.test_invalid_model_config_proto\n","[       OK ] ModelBuilderTF1Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n","[       OK ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF1Test.test_session\n","[  SKIPPED ] ModelBuilderTF1Test.test_session\n","[ RUN      ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n","[       OK ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF1Test.test_unknown_meta_architecture\n","[       OK ] ModelBuilderTF1Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n","[       OK ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 21 tests in 0.154s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G-DHE8xTssqT"},"source":["# Kết nối Cloud Annotations Bucket\n","Để dùng dataset từ IBM, cần phải kết nối tới Colab."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jydTH9gYQ3y7","executionInfo":{"status":"ok","timestamp":1608562670538,"user_tz":-420,"elapsed":35592,"user":{"displayName":"Backdoor Cynet","photoUrl":"","userId":"06118184154984968533"}},"outputId":"0930b56a-bb53-4718-d460-65a05adb3846"},"source":["import cloud_annotations as ca\n","ca.mount(CLOUD_ANNOTATIONS_MOUNT, credentials)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["installing s3fs...\n","done\n","signlook-bucket mounted\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ISX8k0TfdDHj"},"source":["# Tạo label map\n","Các dữ liệu sẽ được lưu trữ thành các dataset và đánh số theo id để máy có thể nhận diện được.\n","\n","Bên dưới ví dụ là cấu trúc của dataset:\n","```\n","item {\n","  id: 1\n","  name: 'Hieu'\n","}\n","\n","item {\n","  id: 2\n","  name: 'Khong hieu'\n","}\n","\n","item {\n","  id: 3\n","  name: 'Xin loi'\n","}\n","```\n"]},{"cell_type":"code","metadata":{"id":"nJsKCG3UdDsn"},"source":["import os\n","import json\n","\n","# Get a list of labels from the annotations.json\n","labels = {}\n","with open(ANNOTATIONS_JSON_PATH) as f:\n","  annotations = json.load(f)\n","  labels = annotations['labels']\n","\n","# Create a file named label_map.pbtxt\n","os.makedirs(DATA_PATH, exist_ok=True)\n","with open(LABEL_MAP_PATH, 'w') as f:\n","  # Loop through all of the labels and write each label to the file with an id\n","  for idx, label in enumerate(labels):\n","    f.write('item {\\n')\n","    f.write(\"\\tname: '{}'\\n\".format(label))\n","    f.write('\\tid: {}\\n'.format(idx + 1)) # indexes must start at 1\n","    f.write('}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"siRNKiuvsz25"},"source":["# Tạo TFRecords\n","Tạo dữ liệu theo format tfrecord cho tf object api có thể sử dụng dataset.\n","```\n","{\n","  'image/height': 1800,\n","  'image/width': 2400,\n","  'image/filename': 'image1.jpg',\n","  'image/source_id': 'image1.jpg',\n","  'image/encoded': ACTUAL_ENCODED_IMAGE_DATA_AS_BYTES,\n","  'image/format': 'jpeg',\n","  'image/object/bbox/xmin': [0.7255949630314233, 0.8845598428835489],\n","  'image/object/bbox/xmax': [0.9695875693160814, 1.0000000000000000],\n","  'image/object/bbox/ymin': [0.5820120073891626, 0.1829972290640394],\n","  'image/object/bbox/ymax': [1.0000000000000000, 0.9662484605911330],\n","  'image/object/class/text': (['Cat', 'Dog']),\n","  'image/object/class/label': ([1, 2])\n","}\n","```"]},{"cell_type":"code","metadata":{"id":"cAkOvP-gZR1x"},"source":["import os\n","import io\n","import json\n","import random\n","\n","import PIL.Image\n","import tensorflow as tf\n","\n","from object_detection.utils import dataset_util\n","from object_detection.utils import label_map_util\n","\n","def create_tf_record(images, annotations, label_map, image_path, output):\n","  # Create a train.record TFRecord file.\n","  with tf.python_io.TFRecordWriter(output) as writer:\n","    # Loop through all the training examples.\n","    for image_name in images:\n","      try:\n","        # Make sure the image is actually a file\n","        img_path = os.path.join(image_path, image_name)   \n","        if not os.path.isfile(img_path):\n","          continue\n","          \n","        # Read in the image.\n","        with tf.gfile.GFile(img_path, 'rb') as fid:\n","          encoded_jpg = fid.read()\n","\n","        # Open the image with PIL so we can check that it's a jpeg and get the image\n","        # dimensions.\n","        encoded_jpg_io = io.BytesIO(encoded_jpg)\n","        image = PIL.Image.open(encoded_jpg_io)\n","        if image.format != 'JPEG':\n","          raise ValueError('Image format not JPEG')\n","\n","        width, height = image.size\n","\n","        # Initialize all the arrays.\n","        xmins = []\n","        xmaxs = []\n","        ymins = []\n","        ymaxs = []\n","        classes_text = []\n","        classes = []\n","\n","        # For each image, loop through all the annotations and append their values.\n","        for a in annotations[image_name]:\n","          if (\"x\" in a and \"x2\" in a and \"y\" in a and \"y2\" in a):\n","            label = a['label']\n","            xmins.append(a[\"x\"])\n","            xmaxs.append(a[\"x2\"])\n","            ymins.append(a[\"y\"])\n","            ymaxs.append(a[\"y2\"])\n","            classes_text.append(label.encode(\"utf8\"))\n","            classes.append(label_map[label])\n","       \n","        # Create the TFExample.\n","        tf_example = tf.train.Example(features=tf.train.Features(feature={\n","          'image/height': dataset_util.int64_feature(height),\n","          'image/width': dataset_util.int64_feature(width),\n","          'image/filename': dataset_util.bytes_feature(image_name.encode('utf8')),\n","          'image/source_id': dataset_util.bytes_feature(image_name.encode('utf8')),\n","          'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","          'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n","          'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","          'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","          'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","          'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","          'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","          'image/object/class/label': dataset_util.int64_list_feature(classes),\n","        }))\n","        if tf_example:\n","          # Write the TFExample to the TFRecord.\n","          writer.write(tf_example.SerializeToString())\n","      except ValueError:\n","        print('Invalid example, ignoring.')\n","        pass\n","      except IOError:\n","        print(\"Can't read example, ignoring.\")\n","        pass\n","\n","with open(ANNOTATIONS_JSON_PATH) as f:\n","  annotations = json.load(f)['annotations']\n","  image_files = [image for image in annotations.keys()]\n","  # Load the label map we created.\n","  label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n","\n","  random.seed(42)\n","  random.shuffle(image_files)\n","  num_train = int(0.7 * len(image_files))\n","  train_examples = image_files[:num_train]\n","  val_examples = image_files[num_train:]\n","\n","  create_tf_record(train_examples, annotations, label_map, CLOUD_ANNOTATIONS_MOUNT, TRAIN_RECORD_PATH)\n","  create_tf_record(val_examples, annotations, label_map, CLOUD_ANNOTATIONS_MOUNT, VAL_RECORD_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n6DhYpAS7gX2"},"source":["# Tải base model\n","\n","Việc đào tạo một mô hình từ đầu có thể tốn thời gian. Để giảm thiểu điều này bằng cách sử dụng điểm kiểm tra mô hình được đào tạo trước. Thay vì bắt đầu từ con số không, chúng ta có thể thêm vào những gì đã học bằng dữ liệu tùy biến.\n","\n","Đây là pretrained model checkpoints tải từ [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)."]},{"cell_type":"code","metadata":{"id":"oHD1Jm0v7jfz"},"source":["import os\n","import tarfile\n","\n","import six.moves.urllib as urllib\n","\n","download_base = 'http://download.tensorflow.org/models/object_detection/'\n","model = MODEL_TYPE + '.tar.gz'\n","tmp = '/content/checkpoint.tar.gz'\n","\n","if not (os.path.exists(CHECKPOINT_PATH)):\n","  # Download the checkpoint\n","  opener = urllib.request.URLopener()\n","  opener.retrieve(download_base + model, tmp)\n","\n","  # Extract all the `model.ckpt` files.\n","  with tarfile.open(tmp) as tar:\n","    for member in tar.getmembers():\n","      member.name = os.path.basename(member.name)\n","      if 'model.ckpt' in member.name:\n","        tar.extract(member, path=CHECKPOINT_PATH)\n","\n","  os.remove(tmp)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UXlvFvwUHrui"},"source":["[link text](https://)# Tùy chỉnh Model\n","\n","Điều cuối cùng cần làm là đưa vào pipeline: số lượng nhãn và nơi để tìm label map, TFRecord và điểm kiểm tra mô hình. Chúng tôi cũng cần thay đổi kích thước lô batch, vì kích thước batch mặc định là 128 quá lớn để Colab xử lý."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8CVExv6HsJS","executionInfo":{"status":"ok","timestamp":1608562712205,"user_tz":-420,"elapsed":77203,"user":{"displayName":"Backdoor Cynet","photoUrl":"","userId":"06118184154984968533"}},"outputId":"b28d75af-af94-4288-a971-2229d5ac850b"},"source":["import re\n","\n","from google.protobuf import text_format\n","\n","from object_detection.utils import config_util\n","from object_detection.utils import label_map_util\n","\n","pipeline_skeleton = '/content/models/research/object_detection/samples/configs/' + CONFIG_TYPE + '.config'\n","configs = config_util.get_configs_from_pipeline_file(pipeline_skeleton)\n","\n","label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n","num_classes = len(label_map.keys())\n","meta_arch = configs[\"model\"].WhichOneof(\"model\")\n","\n","override_dict = {\n","  'model.{}.num_classes'.format(meta_arch): num_classes,\n","  'train_config.batch_size': 32,\n","  'train_input_path': TRAIN_RECORD_PATH,\n","  'eval_input_path': VAL_RECORD_PATH,\n","  'train_config.fine_tune_checkpoint': os.path.join(CHECKPOINT_PATH, 'model.ckpt'),\n","  'label_map_path': LABEL_MAP_PATH\n","}\n","\n","configs = config_util.merge_external_params_with_configs(configs, kwargs_dict=override_dict)\n","pipeline_config = config_util.create_pipeline_proto_from_configs(configs)\n","config_util.save_pipeline_config(pipeline_config, DATA_PATH)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Maybe overwriting model.ssd.num_classes: 9\n","INFO:tensorflow:Maybe overwriting train_config.batch_size: 24\n","INFO:tensorflow:Maybe overwriting train_input_path: /content/data/train.record\n","INFO:tensorflow:Maybe overwriting eval_input_path: /content/data/val.record\n","INFO:tensorflow:Maybe overwriting train_config.fine_tune_checkpoint: /content/checkpoint/model.ckpt\n","INFO:tensorflow:Maybe overwriting label_map_path: /content/data/label_map.pbtxt\n","INFO:tensorflow:Writing pipeline config file to /content/data/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FNYIZK1xVNAa"},"source":["# Bắt đầu huấn luyện\n","Chúng ta có thể bắt đầu quá trình đào tạo bằng cách gọi tập lệnh `model_main`, truyền:\n","- Vị trí của `pipepline.config` đã tạo\n","- Nơi muốn lưu mô hình\n","- Số bước muốn huấn luyện model (đào tạo càng lâu thì càng chính xác)\n","- Số lượng các bước đánh giá (hoặc tần suất kiểm tra mô hình) cho biết mô hình hoạt động tốt như thế nào"]},{"cell_type":"code","metadata":{"id":"Wv5h2bwBVO0V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608563288268,"user_tz":-420,"elapsed":653249,"user":{"displayName":"Backdoor Cynet","photoUrl":"","userId":"06118184154984968533"}},"outputId":"7ac37056-173d-40a0-838b-8f4f74294e17"},"source":["!rm -rf $OUTPUT_PATH\n","!python -m object_detection.model_main \\\n","    --pipeline_config_path=$DATA_PATH/pipeline.config \\\n","    --model_dir=$OUTPUT_PATH \\\n","    --num_train_steps=$NUM_TRAIN_STEPS \\\n","    --num_eval_steps=500"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W1221 14:58:30.910344 140326522623872 model_lib.py:801] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting train_steps: 500\n","I1221 14:58:30.910540 140326522623872 config_util.py:552] Maybe overwriting train_steps: 500\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1221 14:58:30.910639 140326522623872 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I1221 14:58:30.910722 140326522623872 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I1221 14:58:30.910806 140326522623872 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W1221 14:58:30.910914 140326522623872 model_lib.py:817] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","I1221 14:58:30.911026 140326522623872 model_lib.py:852] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","INFO:tensorflow:Using config: {'_model_dir': '/content/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9fd736b048>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I1221 14:58:30.911461 140326522623872 estimator.py:212] Using config: {'_model_dir': '/content/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9fd736b048>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f9fd7361d08>) includes params argument, but params are not passed to Estimator.\n","W1221 14:58:30.911691 140326522623872 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f9fd7361d08>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I1221 14:58:30.912507 140326522623872 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I1221 14:58:30.912690 140326522623872 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I1221 14:58:30.912941 140326522623872 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W1221 14:58:30.917742 140326522623872 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/data/train.record']\n","I1221 14:58:30.948890 140326522623872 dataset_builder.py:148] Reading unweighted datasets: ['/content/data/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/data/train.record']\n","I1221 14:58:30.949740 140326522623872 dataset_builder.py:77] Reading record datasets for input file: ['/content/data/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1221 14:58:30.949879 140326522623872 dataset_builder.py:78] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1221 14:58:30.949964 140326522623872 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W1221 14:58:30.955117 140326522623872 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1221 14:58:30.975724 140326522623872 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f9fd7325ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","W1221 14:58:31.010130 140326522623872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f9fd7325ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fa003fab9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W1221 14:58:31.212971 140326522623872 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fa003fab9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:92: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W1221 14:58:31.214298 140326522623872 deprecation.py:323] From /content/models/research/object_detection/inputs.py:92: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1221 14:58:31.224832 140326522623872 deprecation.py:323] From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W1221 14:58:31.344666 140326522623872 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:264: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1221 14:58:32.081963 140326522623872 deprecation.py:323] From /content/models/research/object_detection/inputs.py:264: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Calling model_fn.\n","I1221 14:58:32.667868 140326522623872 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W1221 14:58:32.681260 140326522623872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 14:58:34.338959 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 14:58:34.369309 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 14:58:34.399135 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 14:58:34.428586 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 14:58:34.458302 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 14:58:34.492036 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n","I1221 14:58:42.652717 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n","I1221 14:58:42.653243 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n","I1221 14:58:42.653615 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n","I1221 14:58:42.654016 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n","I1221 14:58:42.654349 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n","I1221 14:58:42.654691 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n","I1221 14:58:42.655032 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n","I1221 14:58:42.655382 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n","I1221 14:58:42.655713 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n","I1221 14:58:42.656078 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n","I1221 14:58:42.656402 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n","I1221 14:58:42.656722 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n","I1221 14:58:42.657087 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n","I1221 14:58:42.657426 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n","I1221 14:58:42.657740 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n","I1221 14:58:42.658095 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n","I1221 14:58:42.658400 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n","I1221 14:58:42.658777 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n","I1221 14:58:42.659120 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n","I1221 14:58:42.659464 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n","I1221 14:58:42.659804 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n","I1221 14:58:42.660168 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n","I1221 14:58:42.660492 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n","I1221 14:58:42.660842 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n","I1221 14:58:42.661171 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n","I1221 14:58:42.661503 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n","I1221 14:58:42.661835 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n","INFO:tensorflow:Done calling model_fn.\n","I1221 14:58:48.495380 140326522623872 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I1221 14:58:48.496753 140326522623872 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I1221 14:58:51.606479 140326522623872 monitored_session.py:240] Graph was finalized.\n","2020-12-21 14:58:51.617518: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-12-21 14:58:51.617748: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16575f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-12-21 14:58:51.617788: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-12-21 14:58:51.622881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-12-21 14:58:51.818878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 14:58:51.819684: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16575dc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-12-21 14:58:51.819720: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-12-21 14:58:51.820902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 14:58:51.821503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 14:58:51.821879: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 14:58:52.050113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 14:58:52.176804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 14:58:52.216038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 14:58:52.466717: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 14:58:52.514531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 14:58:52.975617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 14:58:52.975847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 14:58:52.976646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 14:58:52.977180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 14:58:52.980199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 14:58:52.981745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-21 14:58:52.981778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-21 14:58:52.981790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-21 14:58:53.010368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 14:58:53.011116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 14:58:53.011861: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-12-21 14:58:53.011920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Running local_init_op.\n","I1221 14:59:02.906963 140326522623872 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1221 14:59:03.257254 140326522623872 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/output/model.ckpt.\n","I1221 14:59:12.483944 140326522623872 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /content/output/model.ckpt.\n","2020-12-21 14:59:27.822917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 14:59:34.517564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","INFO:tensorflow:loss = 4.1130056, step = 0\n","I1221 14:59:42.558978 140326522623872 basic_session_run_hooks.py:262] loss = 4.1130056, step = 0\n","INFO:tensorflow:global_step/sec: 0.952864\n","I1221 15:01:27.504997 140326522623872 basic_session_run_hooks.py:692] global_step/sec: 0.952864\n","INFO:tensorflow:loss = 1.5089743, step = 100 (104.947 sec)\n","I1221 15:01:27.506282 140326522623872 basic_session_run_hooks.py:260] loss = 1.5089743, step = 100 (104.947 sec)\n","INFO:tensorflow:global_step/sec: 1.08101\n","I1221 15:03:00.011312 140326522623872 basic_session_run_hooks.py:692] global_step/sec: 1.08101\n","INFO:tensorflow:loss = 1.0259509, step = 200 (92.506 sec)\n","I1221 15:03:00.012550 140326522623872 basic_session_run_hooks.py:260] loss = 1.0259509, step = 200 (92.506 sec)\n","INFO:tensorflow:global_step/sec: 1.07451\n","I1221 15:04:33.077197 140326522623872 basic_session_run_hooks.py:692] global_step/sec: 1.07451\n","INFO:tensorflow:loss = 1.0886778, step = 300 (93.066 sec)\n","I1221 15:04:33.078412 140326522623872 basic_session_run_hooks.py:260] loss = 1.0886778, step = 300 (93.066 sec)\n","INFO:tensorflow:global_step/sec: 1.0764\n","I1221 15:06:05.979332 140326522623872 basic_session_run_hooks.py:692] global_step/sec: 1.0764\n","INFO:tensorflow:loss = 0.90986335, step = 400 (92.902 sec)\n","I1221 15:06:05.980514 140326522623872 basic_session_run_hooks.py:260] loss = 0.90986335, step = 400 (92.902 sec)\n","INFO:tensorflow:Saving checkpoints for 500 into /content/output/model.ckpt.\n","I1221 15:07:38.265957 140326522623872 basic_session_run_hooks.py:606] Saving checkpoints for 500 into /content/output/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/data/val.record']\n","I1221 15:07:39.654352 140326522623872 dataset_builder.py:148] Reading unweighted datasets: ['/content/data/val.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/data/val.record']\n","I1221 15:07:39.655411 140326522623872 dataset_builder.py:77] Reading record datasets for input file: ['/content/data/val.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1221 15:07:39.655551 140326522623872 dataset_builder.py:78] Number of filenames to read: 1\n","WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f9fc4156da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","W1221 15:07:39.699489 140326522623872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f9fc4156da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f9fcfdb8598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W1221 15:07:39.878223 140326522623872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f9fcfdb8598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I1221 15:07:40.427517 140326522623872 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:41.820775 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:41.849364 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:41.878049 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:41.905791 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:41.933613 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:41.962445 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n","I1221 15:07:43.964504 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n","I1221 15:07:43.964852 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n","I1221 15:07:43.965086 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n","I1221 15:07:43.965306 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n","I1221 15:07:43.965489 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n","I1221 15:07:43.965677 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n","I1221 15:07:43.965854 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n","I1221 15:07:43.966072 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n","I1221 15:07:43.966259 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n","I1221 15:07:43.966451 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n","I1221 15:07:43.966639 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n","I1221 15:07:43.966830 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n","I1221 15:07:43.967003 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n","I1221 15:07:43.967216 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n","I1221 15:07:43.967381 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n","I1221 15:07:43.967592 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n","I1221 15:07:43.967783 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n","I1221 15:07:43.967962 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n","I1221 15:07:43.968153 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n","I1221 15:07:43.968334 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n","I1221 15:07:43.968506 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n","I1221 15:07:43.968690 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n","I1221 15:07:43.968862 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n","I1221 15:07:43.969051 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n","I1221 15:07:43.969263 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n","I1221 15:07:43.969442 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n","I1221 15:07:43.969619 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n","I1221 15:07:43.969788 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n","I1221 15:07:43.969960 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n","I1221 15:07:43.970144 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n","I1221 15:07:43.970338 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n","I1221 15:07:43.970512 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n","I1221 15:07:43.970690 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n","I1221 15:07:43.970862 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n","I1221 15:07:43.971048 140326522623872 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1221 15:07:43.998265 140326522623872 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W1221 15:07:44.194036 140326522623872 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Done calling model_fn.\n","I1221 15:07:44.745728 140326522623872 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-12-21T15:07:44Z\n","I1221 15:07:44.762427 140326522623872 evaluation.py:255] Starting evaluation at 2020-12-21T15:07:44Z\n","INFO:tensorflow:Graph was finalized.\n","I1221 15:07:45.246231 140326522623872 monitored_session.py:240] Graph was finalized.\n","2020-12-21 15:07:45.247668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:07:45.248047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 15:07:45.248204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:07:45.248268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 15:07:45.248304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 15:07:45.248346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 15:07:45.248373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 15:07:45.248401: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 15:07:45.248433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 15:07:45.248536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:07:45.248858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:07:45.249154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 15:07:45.249278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-21 15:07:45.249296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-21 15:07:45.249308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-21 15:07:45.249432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:07:45.249739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:07:45.250018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n","I1221 15:07:45.251166 140326522623872 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n","INFO:tensorflow:Running local_init_op.\n","I1221 15:07:46.281478 140326522623872 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1221 15:07:46.420671 140326522623872 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 64 images.\n","I1221 15:07:54.230922 140324109817600 coco_evaluation.py:282] Performing evaluation on 64 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I1221 15:07:54.231520 140324109817600 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.01s)\n","I1221 15:07:54.237043 140324109817600 coco_tools.py:138] DONE (t=0.01s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.34s).\n","Accumulating evaluation results...\n","DONE (t=0.16s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.975\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.380\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.505\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.576\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.576\n","INFO:tensorflow:Finished evaluation at 2020-12-21-15:07:56\n","I1221 15:07:56.083030 140326522623872 evaluation.py:275] Finished evaluation at 2020-12-21-15:07:56\n","INFO:tensorflow:Saving dict for global step 500: DetectionBoxes_Precision/mAP = 0.48220187, DetectionBoxes_Precision/mAP (large) = 0.4822073, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9752475, DetectionBoxes_Precision/mAP@.75IOU = 0.37992838, DetectionBoxes_Recall/AR@1 = 0.5052645, DetectionBoxes_Recall/AR@10 = 0.57181215, DetectionBoxes_Recall/AR@100 = 0.57625663, DetectionBoxes_Recall/AR@100 (large) = 0.57625663, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.29127544, Loss/localization_loss = 0.18692249, Loss/regularization_loss = 0.41016582, Loss/total_loss = 0.888364, global_step = 500, learning_rate = 0.095, loss = 0.888364\n","I1221 15:07:56.083355 140326522623872 estimator.py:2049] Saving dict for global step 500: DetectionBoxes_Precision/mAP = 0.48220187, DetectionBoxes_Precision/mAP (large) = 0.4822073, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9752475, DetectionBoxes_Precision/mAP@.75IOU = 0.37992838, DetectionBoxes_Recall/AR@1 = 0.5052645, DetectionBoxes_Recall/AR@10 = 0.57181215, DetectionBoxes_Recall/AR@100 = 0.57625663, DetectionBoxes_Recall/AR@100 (large) = 0.57625663, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.29127544, Loss/localization_loss = 0.18692249, Loss/regularization_loss = 0.41016582, Loss/total_loss = 0.888364, global_step = 500, learning_rate = 0.095, loss = 0.888364\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: /content/output/model.ckpt-500\n","I1221 15:07:56.872403 140326522623872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 500: /content/output/model.ckpt-500\n","INFO:tensorflow:Performing the final export in the end of training.\n","I1221 15:07:56.873264 140326522623872 exporter.py:410] Performing the final export in the end of training.\n","INFO:tensorflow:Calling model_fn.\n","I1221 15:07:57.145028 140326522623872 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:58.542428 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:58.572294 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:58.602084 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:58.629978 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:58.658982 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:07:58.687477 140326522623872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I1221 15:07:59.517319 140326522623872 estimator.py:1150] Done calling model_fn.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W1221 15:07:59.517612 140326522623872 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","I1221 15:07:59.518252 140326522623872 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","I1221 15:07:59.518402 140326522623872 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I1221 15:07:59.518495 140326522623872 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","I1221 15:07:59.518574 140326522623872 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","I1221 15:07:59.518659 140326522623872 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","2020-12-21 15:07:59.519218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:07:59.519547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 15:07:59.519636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:07:59.519664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 15:07:59.519690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 15:07:59.519716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 15:07:59.519741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 15:07:59.519764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 15:07:59.519788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 15:07:59.519880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:07:59.520259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:07:59.520512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 15:07:59.520552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-21 15:07:59.520566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-21 15:07:59.520576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-21 15:07:59.520675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:07:59.520974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:07:59.521289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n","I1221 15:07:59.523523 140326522623872 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n","INFO:tensorflow:Assets added to graph.\n","I1221 15:07:59.824574 140326522623872 builder_impl.py:665] Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","I1221 15:07:59.824784 140326522623872 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /content/output/export/Servo/temp-b'1608563276'/saved_model.pb\n","I1221 15:08:00.378967 140326522623872 builder_impl.py:425] SavedModel written to: /content/output/export/Servo/temp-b'1608563276'/saved_model.pb\n","INFO:tensorflow:Loss for final step: 0.9202066.\n","I1221 15:08:00.767414 140326522623872 estimator.py:371] Loss for final step: 0.9202066.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AwNtvgtdoB-C"},"source":["# Xuất inference graph\n","\n","Sau khi mô hình của bạn đã được đào tạo, bạn có thể có một vài điểm kiểm tra. Một điểm kiểm tra thường được phát ra sau mỗi 500 bước đào tạo. Mỗi điểm kiểm tra là một ảnh chụp nhanh mô hình của bạn tại thời điểm đó trong quá trình đào tạo. Trong trường hợp quá trình đào tạo đang chạy dài bị lỗi, có thể chọn ở điểm kiểm tra cuối cùng thay vì bắt đầu lại từ đầu.\n","\n"]},{"cell_type":"code","metadata":{"id":"BZgP_FZUoE0d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608563303205,"user_tz":-420,"elapsed":668176,"user":{"displayName":"Backdoor Cynet","photoUrl":"","userId":"06118184154984968533"}},"outputId":"e5997f04-0dba-4dbf-a0b5-d0fef9de7d09"},"source":["import os\n","import re\n","\n","regex = re.compile(r\"model\\.ckpt-([0-9]+)\\.index\")\n","numbers = [int(regex.search(f).group(1)) for f in os.listdir(OUTPUT_PATH) if regex.search(f)]\n","TRAINED_CHECKPOINT_PREFIX = os.path.join(OUTPUT_PATH, 'model.ckpt-{}'.format(max(numbers)))\n","\n","print(f'Using {TRAINED_CHECKPOINT_PREFIX}')\n","\n","!rm -rf $EXPORTED_PATH\n","!python -m object_detection.export_inference_graph \\\n","  --pipeline_config_path=$DATA_PATH/pipeline.config \\\n","  --trained_checkpoint_prefix=$TRAINED_CHECKPOINT_PREFIX \\\n","  --output_directory=$EXPORTED_PATH"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using /content/output/model.ckpt-500\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W1221 15:08:06.178596 140091111151488 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:08:07.615123 140091111151488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:08:07.652612 140091111151488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:08:07.690379 140091111151488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:08:07.727693 140091111151488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:08:07.767159 140091111151488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1221 15:08:07.806556 140091111151488 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:595: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W1221 15:08:08.081176 140091111151488 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:595: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W1221 15:08:08.816992 140091111151488 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n","I1221 15:08:09.753758 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n","I1221 15:08:09.754189 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n","I1221 15:08:09.754461 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n","I1221 15:08:09.754680 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n","I1221 15:08:09.754890 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n","I1221 15:08:09.755124 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n","I1221 15:08:09.755363 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n","I1221 15:08:09.755570 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n","I1221 15:08:09.755753 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n","I1221 15:08:09.755951 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n","I1221 15:08:09.756187 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n","I1221 15:08:09.756419 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n","I1221 15:08:09.756613 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n","I1221 15:08:09.756820 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n","I1221 15:08:09.757033 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n","I1221 15:08:09.757237 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n","I1221 15:08:09.757444 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n","I1221 15:08:09.757622 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n","I1221 15:08:09.757797 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n","I1221 15:08:09.757987 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n","I1221 15:08:09.758209 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n","I1221 15:08:09.758444 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n","I1221 15:08:09.758619 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n","I1221 15:08:09.758800 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n","I1221 15:08:09.758975 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n","I1221 15:08:09.759193 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n","I1221 15:08:09.759387 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n","I1221 15:08:09.759581 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n","I1221 15:08:09.759768 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n","I1221 15:08:09.759958 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n","I1221 15:08:09.760164 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n","I1221 15:08:09.760356 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n","I1221 15:08:09.760541 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n","I1221 15:08:09.760733 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n","I1221 15:08:09.760923 140091111151488 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W1221 15:08:09.762550 140091111151488 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W1221 15:08:09.762980 140091111151488 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","194 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/5.61m params)\n","  BoxPredictor_0 (--/21.55k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n","    BoxPredictor_0/ClassPredictor (--/15.39k params)\n","      BoxPredictor_0/ClassPredictor/biases (30, 30/30 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x512x30, 15.36k/15.36k params)\n","  BoxPredictor_1 (--/86.10k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n","    BoxPredictor_1/ClassPredictor (--/61.50k params)\n","      BoxPredictor_1/ClassPredictor/biases (60, 60/60 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1024x60, 61.44k/61.44k params)\n","  BoxPredictor_2 (--/43.09k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/30.78k params)\n","      BoxPredictor_2/ClassPredictor/biases (60, 60/60 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x60, 30.72k/30.72k params)\n","  BoxPredictor_3 (--/21.59k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/15.42k params)\n","      BoxPredictor_3/ClassPredictor/biases (60, 60/60 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x60, 15.36k/15.36k params)\n","  BoxPredictor_4 (--/21.59k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/15.42k params)\n","      BoxPredictor_4/ClassPredictor/biases (60, 60/60 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x60, 15.36k/15.36k params)\n","  BoxPredictor_5 (--/10.84k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/7.74k params)\n","      BoxPredictor_5/ClassPredictor/biases (60, 60/60 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x60, 7.68k/7.68k params)\n","  FeatureExtractor (--/5.41m params)\n","    FeatureExtractor/MobilenetV1 (--/5.41m params)\n","      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n","      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","\n","======================End of Report==========================\n","194 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/5.42m flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/mul_fold (1.18m/1.18m flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/mul_fold (1.05m/1.05m flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/mul_fold (524.29k/524.29k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/mul_fold (131.07k/131.07k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/mul_fold (73.73k/73.73k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/mul_fold (65.54k/65.54k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/mul_fold (65.54k/65.54k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/mul_fold (32.77k/32.77k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/mul_fold (32.77k/32.77k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/mul_fold (16.38k/16.38k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/mul_fold (16.38k/16.38k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/mul_fold (9.22k/9.22k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/mul_fold (8.19k/8.19k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/mul_fold (2.30k/2.30k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/mul_fold (2.30k/2.30k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/mul_fold (2.05k/2.05k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/mul_fold (1.15k/1.15k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/mul_fold (1.15k/1.15k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/mul_fold (864/864 flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/mul_fold (576/576 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/mul_fold (288/288 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","\n","======================End of Report==========================\n","2020-12-21 15:08:12.051157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-12-21 15:08:12.101363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:12.101969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 15:08:12.102270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:08:12.104374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 15:08:12.106333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 15:08:12.107231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 15:08:12.116811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 15:08:12.127866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 15:08:12.169682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 15:08:12.169857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:12.170646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:12.171271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 15:08:12.177475: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-12-21 15:08:12.177749: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2862d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-12-21 15:08:12.177784: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-12-21 15:08:12.300048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:12.300825: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2862f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-12-21 15:08:12.300864: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-12-21 15:08:12.301103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:12.301681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 15:08:12.301764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:08:12.301799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 15:08:12.301830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 15:08:12.301858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 15:08:12.301884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 15:08:12.301924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 15:08:12.301946: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 15:08:12.302048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:12.302663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:12.303212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 15:08:12.303290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:08:12.304584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-21 15:08:12.304615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-21 15:08:12.304626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-21 15:08:12.304745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:12.305406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:12.305956: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-12-21 15:08:12.305996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n","I1221 15:08:12.308133 140091111151488 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W1221 15:08:14.097417 140091111151488 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-12-21 15:08:14.848242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:14.848856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 15:08:14.848974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:08:14.849026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 15:08:14.849053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 15:08:14.849092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 15:08:14.849112: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 15:08:14.849136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 15:08:14.849159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 15:08:14.849255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:14.849848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:14.850420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 15:08:14.850468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-21 15:08:14.850483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-21 15:08:14.850510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-21 15:08:14.850629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:14.851255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:14.851803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n","I1221 15:08:14.853152 140091111151488 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W1221 15:08:15.584509 140091111151488 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W1221 15:08:15.584801 140091111151488 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 387 variables.\n","I1221 15:08:15.999522 140091111151488 graph_util_impl.py:334] Froze 387 variables.\n","INFO:tensorflow:Converted 387 variables to const ops.\n","I1221 15:08:16.089238 140091111151488 graph_util_impl.py:394] Converted 387 variables to const ops.\n","2020-12-21 15:08:16.245482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:16.246112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 15:08:16.246221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:08:16.246258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 15:08:16.246280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 15:08:16.246307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 15:08:16.246342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 15:08:16.246361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 15:08:16.246384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 15:08:16.246494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:16.247158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:16.247721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 15:08:16.247766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-21 15:08:16.247796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-21 15:08:16.247807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-21 15:08:16.247913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:16.248512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:08:16.249134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W1221 15:08:16.706152 140091111151488 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:No assets to save.\n","I1221 15:08:16.707048 140091111151488 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I1221 15:08:16.707208 140091111151488 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /content/exported/saved_model/saved_model.pb\n","I1221 15:08:16.995043 140091111151488 builder_impl.py:425] SavedModel written to: /content/exported/saved_model/saved_model.pb\n","INFO:tensorflow:Writing pipeline config file to /content/exported/pipeline.config\n","I1221 15:08:17.021806 140091111151488 config_util.py:254] Writing pipeline config file to /content/exported/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yVmCc9NPkP3U"},"source":["# Chuyển đổi sang tfjs\n","Để sử dụng model trên web broswer\n"]},{"cell_type":"code","metadata":{"id":"A-f5lfcnp01e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608563309431,"user_tz":-420,"elapsed":674385,"user":{"displayName":"Backdoor Cynet","photoUrl":"","userId":"06118184154984968533"}},"outputId":"b941383c-b7f9-4a31-b0cf-afe2d75394d4"},"source":["!tensorflowjs_converter \\\n","  --input_format=tf_frozen_model \\\n","  --output_format=tfjs_graph_model \\\n","  --output_node_names='Postprocessor/ExpandDims_1,Postprocessor/Slice' \\\n","  --quantization_bytes=1 \\\n","  --skip_op_check \\\n","  $EXPORTED_PATH/frozen_inference_graph.pb \\\n","  /content/model_web\n","\n","import json\n","\n","from object_detection.utils.label_map_util import get_label_map_dict\n","\n","label_map = get_label_map_dict(LABEL_MAP_PATH)\n","label_array = [k for k in sorted(label_map, key=label_map.get)]\n","\n","with open(os.path.join('/content/model_web', 'labels.json'), 'w') as f:\n","  json.dump(label_array, f)\n","\n","!cd /content/model_web && zip -r /content/model_web.zip *"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-12-21 15:08:20.992350: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n","2020-12-21 15:08:20.992411: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   debug_stripper: Graph size after: 3565 nodes (0), 4556 edges (0), time = 3.051ms.\n","2020-12-21 15:08:20.992423: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 2100 nodes (-1465), 2355 edges (-2201), time = 18.037ms.\n","2020-12-21 15:08:20.992438: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 625 nodes (-1475), 687 edges (-1668), time = 237.36ms.\n","2020-12-21 15:08:20.992451: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 482 nodes (-143), 646 edges (-41), time = 40.307ms.\n","2020-12-21 15:08:20.992463: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 476 nodes (-6), 639 edges (-7), time = 10.58ms.\n","2020-12-21 15:08:20.992476: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 476 nodes (0), 639 edges (0), time = 14.685ms.\n","2020-12-21 15:08:20.992488: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 476 nodes (0), 639 edges (0), time = 86.155ms.\n","2020-12-21 15:08:20.992500: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 474 nodes (-2), 635 edges (-4), time = 38.515ms.\n","2020-12-21 15:08:20.992512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 474 nodes (0), 635 edges (0), time = 11.039ms.\n","2020-12-21 15:08:20.992524: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   debug_stripper: debug_stripper did nothing. time = 0.729ms.\n","2020-12-21 15:08:20.992536: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 474 nodes (0), 635 edges (0), time = 14.349ms.\n","2020-12-21 15:08:20.992548: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 474 nodes (0), 635 edges (0), time = 49.121ms.\n","2020-12-21 15:08:20.992560: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 474 nodes (0), 635 edges (0), time = 38.428ms.\n","2020-12-21 15:08:20.992572: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 474 nodes (0), 635 edges (0), time = 10.358ms.\n","2020-12-21 15:08:20.992584: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 474 nodes (0), 635 edges (0), time = 16.885ms.\n","2020-12-21 15:08:20.992596: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 474 nodes (0), 635 edges (0), time = 47.658ms.\n","2020-12-21 15:08:20.992608: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 474 nodes (0), 635 edges (0), time = 39.145ms.\n","2020-12-21 15:08:20.992620: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 474 nodes (0), 635 edges (0), time = 10.878ms.\n","2020-12-21 15:08:21.844473: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n","2020-12-21 15:08:21.844534: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   remapper: Graph size after: 462 nodes (-12), 623 edges (-12), time = 20.712ms.\n","2020-12-21 15:08:21.844546: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 462 nodes (0), 623 edges (0), time = 54.77ms.\n","2020-12-21 15:08:21.844562: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 462 nodes (0), 623 edges (0), time = 38.994ms.\n","2020-12-21 15:08:21.844574: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 462 nodes (0), 623 edges (0), time = 9.797ms.\n","2020-12-21 15:08:21.844586: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   remapper: Graph size after: 462 nodes (0), 623 edges (0), time = 15.493ms.\n","2020-12-21 15:08:21.844599: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 462 nodes (0), 623 edges (0), time = 47.234ms.\n","2020-12-21 15:08:21.844610: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 462 nodes (0), 623 edges (0), time = 38.378ms.\n","2020-12-21 15:08:21.844622: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 462 nodes (0), 623 edges (0), time = 10.736ms.\n","Writing weight file /content/model_web/model.json...\n","  adding: group1-shard1of2.bin (deflated 26%)\n","  adding: group1-shard2of2.bin (deflated 24%)\n","  adding: labels.json (deflated 24%)\n","  adding: model.json (deflated 93%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q1iFI9pPr1l7"},"source":["# Tải model tfjs"]},{"cell_type":"code","metadata":{"id":"FL_miSj2r1yt"},"source":["from google.colab import files\n","files.download('/content/model_web.zip') "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x6_NRANdhxO4"},"source":["# Chuyển đổi sang tflite"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9R2Kdf7QwS2M","executionInfo":{"status":"ok","timestamp":1608563309733,"user_tz":-420,"elapsed":674667,"user":{"displayName":"Backdoor Cynet","photoUrl":"","userId":"06118184154984968533"}},"outputId":"715d8e4a-60a4-423c-eb9f-1794fc10ca2c"},"source":["%cd /content\r\n","!mkdir model_android"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQBaaklPtvpO","executionInfo":{"status":"ok","timestamp":1608563694312,"user_tz":-420,"elapsed":4330,"user":{"displayName":"Backdoor Cynet","photoUrl":"","userId":"06118184154984968533"}},"outputId":"5b1e513f-6839-4537-ab86-c28821877bf0"},"source":["%%bash\r\n","python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\r\n","    --pipeline_config_path /content/data/pipeline.config \\\r\n","    --trained_checkpoint_dir /content/output/checkpoint \\\r\n","    --output_directory /content/model_android"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/content/models/research/object_detection/export_tflite_graph_tf2.py\", line 126, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/models/research/object_detection/export_tflite_graph_tf2.py\", line 122, in main\n","    FLAGS.ssd_use_regular_nms)\n","  File \"/content/models/research/object_detection/export_tflite_graph_lib_tf2.py\", line 231, in export_tflite_model\n","    pipeline_config.model, is_training=False)\n","  File \"/content/models/research/object_detection/builders/model_builder.py\", line 1090, in build\n","    add_summaries)\n","  File \"/content/models/research/object_detection/builders/model_builder.py\", line 380, in _build_ssd_model\n","    is_training=is_training)\n","  File \"/content/models/research/object_detection/builders/model_builder.py\", line 293, in _build_ssd_feature_extractor\n","    feature_extractor_class = SSD_KERAS_FEATURE_EXTRACTOR_CLASS_MAP[\n","NameError: name 'SSD_KERAS_FEATURE_EXTRACTOR_CLASS_MAP' is not defined\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9nl2StC7oW5S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608563780733,"user_tz":-420,"elapsed":4700,"user":{"displayName":"Backdoor Cynet","photoUrl":"","userId":"06118184154984968533"}},"outputId":"5c8afd90-8d9e-4088-c173-dc0f2a5a9bee"},"source":["!tflite_convert --saved_model_dir=/content/exported/saved_model --output_file= /content/model_android/model.tflite"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-12-21 15:16:13.456820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-12-21 15:16:13.492857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:13.493519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 15:16:13.493813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:16:13.495684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 15:16:13.497414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 15:16:13.497753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 15:16:13.499683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 15:16:13.500806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 15:16:13.504779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 15:16:13.504892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:13.505525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:13.506063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 15:16:13.511308: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-12-21 15:16:13.511491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x247ca00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-12-21 15:16:13.511521: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-12-21 15:16:13.624446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:13.625186: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x247cf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-12-21 15:16:13.625218: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-12-21 15:16:13.625379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:13.625924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 15:16:13.625979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:16:13.626000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 15:16:13.626060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 15:16:13.626082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 15:16:13.626110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 15:16:13.626130: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 15:16:13.626151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 15:16:13.626221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:13.626850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:13.627440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 15:16:13.627508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:16:13.628582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-21 15:16:13.628609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-21 15:16:13.628620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-21 15:16:13.628724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:13.629345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:13.629902: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-12-21 15:16:13.629944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n","W1221 15:16:13.630733 140357316675456 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","I1221 15:16:14.200814 140357316675456 saver.py:1503] Saver not created because there are no variables in the graph to restore\n","INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n","I1221 15:16:14.201094 140357316675456 loader_impl.py:374] The specified SavedModel has no variables; no checkpoints were restored.\n","INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n","I1221 15:16:14.201701 140357316675456 convert_saved_model.py:80] The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n","INFO:tensorflow:input tensors info: \n","I1221 15:16:14.202448 140357316675456 convert_saved_model.py:99] input tensors info: \n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: inputs\n","I1221 15:16:14.202599 140357316675456 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: inputs\n","INFO:tensorflow: tensor name: image_tensor:0, shape: (-1, -1, -1, 3), type: DT_UINT8\n","I1221 15:16:14.203027 140357316675456 convert_saved_model.py:43]  tensor name: image_tensor:0, shape: (-1, -1, -1, 3), type: DT_UINT8\n","INFO:tensorflow:output tensors info: \n","I1221 15:16:14.203126 140357316675456 convert_saved_model.py:101] output tensors info: \n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_classes\n","I1221 15:16:14.203276 140357316675456 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: detection_classes\n","INFO:tensorflow: tensor name: detection_classes:0, shape: (-1, 100), type: DT_FLOAT\n","I1221 15:16:14.203373 140357316675456 convert_saved_model.py:43]  tensor name: detection_classes:0, shape: (-1, 100), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: num_detections\n","I1221 15:16:14.203471 140357316675456 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: num_detections\n","INFO:tensorflow: tensor name: num_detections:0, shape: (-1), type: DT_FLOAT\n","I1221 15:16:14.203565 140357316675456 convert_saved_model.py:43]  tensor name: num_detections:0, shape: (-1), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_boxes\n","I1221 15:16:14.203659 140357316675456 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: detection_boxes\n","INFO:tensorflow: tensor name: detection_boxes:0, shape: (-1, 100, 4), type: DT_FLOAT\n","I1221 15:16:14.203742 140357316675456 convert_saved_model.py:43]  tensor name: detection_boxes:0, shape: (-1, 100, 4), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: raw_detection_boxes\n","I1221 15:16:14.203840 140357316675456 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: raw_detection_boxes\n","INFO:tensorflow: tensor name: raw_detection_boxes:0, shape: (-1, -1, 4), type: DT_FLOAT\n","I1221 15:16:14.203923 140357316675456 convert_saved_model.py:43]  tensor name: raw_detection_boxes:0, shape: (-1, -1, 4), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_scores\n","I1221 15:16:14.204035 140357316675456 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: detection_scores\n","INFO:tensorflow: tensor name: detection_scores:0, shape: (-1, 100), type: DT_FLOAT\n","I1221 15:16:14.204122 140357316675456 convert_saved_model.py:43]  tensor name: detection_scores:0, shape: (-1, 100), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: raw_detection_scores\n","I1221 15:16:14.204212 140357316675456 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: raw_detection_scores\n","INFO:tensorflow: tensor name: raw_detection_scores:0, shape: (-1, -1, 10), type: DT_FLOAT\n","I1221 15:16:14.204302 140357316675456 convert_saved_model.py:43]  tensor name: raw_detection_scores:0, shape: (-1, -1, 10), type: DT_FLOAT\n","INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_multiclass_scores\n","I1221 15:16:14.204396 140357316675456 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: detection_multiclass_scores\n","INFO:tensorflow: tensor name: detection_multiclass_scores:0, shape: (-1, 100, 10), type: DT_FLOAT\n","I1221 15:16:14.204479 140357316675456 convert_saved_model.py:43]  tensor name: detection_multiclass_scores:0, shape: (-1, 100, 10), type: DT_FLOAT\n","2020-12-21 15:16:14.205188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.205839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 15:16:14.205909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:16:14.205934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 15:16:14.205958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 15:16:14.205982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 15:16:14.206004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 15:16:14.206051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 15:16:14.206080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 15:16:14.206165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.206810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.207458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 15:16:14.207509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-21 15:16:14.207529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-21 15:16:14.207545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-21 15:16:14.207652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.208296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.208868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","I1221 15:16:14.836280 140357316675456 saver.py:1503] Saver not created because there are no variables in the graph to restore\n","INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n","I1221 15:16:14.836549 140357316675456 loader_impl.py:374] The specified SavedModel has no variables; no checkpoints were restored.\n","2020-12-21 15:16:14.924353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.924911: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n","2020-12-21 15:16:14.925056: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n","2020-12-21 15:16:14.925671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.926292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-21 15:16:14.926353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-21 15:16:14.926376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-21 15:16:14.926396: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-21 15:16:14.926415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-21 15:16:14.926438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-21 15:16:14.926457: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-21 15:16:14.926475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-21 15:16:14.926537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.927144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.927707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-21 15:16:14.927748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-21 15:16:14.927764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-21 15:16:14.927775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-21 15:16:14.927875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.928501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-21 15:16:14.929055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2020-12-21 15:16:14.997540: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n","2020-12-21 15:16:14.997598: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.006ms.\n","2020-12-21 15:16:14.997609: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.2/python3.6/bin/tflite_convert\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\n","    app.run(main=run_main, argv=sys.argv[:1])\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\n","    _convert_tf1_model(tflite_flags)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/tflite_convert.py\", line 199, in _convert_tf1_model\n","    output_data = converter.convert()\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/lite.py\", line 896, in convert\n","    _get_tensor_name(tensor), shape_list))\n","ValueError: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u7VWA97xomjZ"},"source":["# Tải model tflite "]},{"cell_type":"code","metadata":{"id":"NXFeTHmnol2R"},"source":["from google.colab import files\r\n","files.download('/content/model_android')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P3WHwIZ0QlVP"},"source":["# Sử dụng model\n","Dùng `model_web` và `model_android` đã tải xuống, tham khảo template của IBM để chạy thử [mô hình javascript](https://github.com/cloud-annotations/object-detection-react)  hoặc [mô hình Android](https://github.com/cloud-annotations/object-detection-android)"]},{"cell_type":"markdown","metadata":{"id":"EhlHH-bm1BHn"},"source":["# Tài liệu tham khảo\r\n","- https://cloud.annotations.ai/workshops/object-detection/6.html\r\n","- https://cloud.annotations.ai/buckets/"]}]}